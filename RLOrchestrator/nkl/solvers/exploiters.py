"""
NKL Exploiter Variants - Configured for CONVERGENCE and LOCAL REFINEMENT.

All exploiters are tuned to:
- Strong attraction toward best solutions
- High selection pressure
- Low mutation rates
- Local search operations
- Quick convergence to local optima

Key tuning principles:
- Low randomness / perturbation
- High selection pressure
- Low mutation rates
- Strong attraction to best solutions
"""

from __future__ import annotations

import math
from typing import List, Optional, Dict, Tuple
from dataclasses import dataclass

import numpy as np

from Core.problem import ProblemInterface, Solution
from Core.search_algorithm import SearchAlgorithm


# =============================================================================
# Binary Conversion Mixin
# =============================================================================

class BinaryMixin:
    """Provides binary conversion for continuous-valued algorithms."""
    
    def _to_binary(self, vector: np.ndarray) -> np.ndarray:
        """Convert continuous [0,1] vector to binary using threshold."""
        return (np.asarray(vector) >= 0.5).astype(int)
    
    def _to_continuous(self, binary: np.ndarray) -> np.ndarray:
        """Convert binary to continuous (just cast to float)."""
        return np.asarray(binary, dtype=float)
    
    def _binary_solution(self, vector: np.ndarray) -> Solution:
        """Create binary solution from continuous vector."""
        binary = self._to_binary(vector)
        sol = Solution(binary.tolist(), self.problem)
        sol.evaluate()
        return sol
    
    def _random_binary(self, dim: int) -> np.ndarray:
        """Generate random binary vector."""
        return self.rng.integers(0, 2, size=dim, dtype=int)
    
    def _bit_flip_mutation(self, binary: np.ndarray, rate: float) -> np.ndarray:
        """Flip bits with given probability."""
        mask = self.rng.random(len(binary)) < rate
        result = binary.copy()
        result[mask] = 1 - result[mask]
        return result


# =============================================================================
# Binary PSO Exploiter - Strong convergence via deterministic bit-flips
# =============================================================================

class NKLBinaryPSOExploiter(SearchAlgorithm):
    """
    Binary Particle Swarm Optimization for PURE EXPLOITATION.
    
    Uses deterministic bit-flip based on velocity sign for strong convergence.
    """
    phase = "exploitation"

    def __init__(self, problem: ProblemInterface, population_size: int, 
                 omega: float = 0.7, c1: float = 1.5, c2: float = 2.0, 
                 vmax: float = 4.0, seed: Optional[int] = None, **kwargs):
        super().__init__(problem, population_size, **kwargs)
        self.omega = omega
        self.c1 = c1
        self.c2 = c2
        self.vmax = vmax
        self.rng = np.random.default_rng(seed)
        
        self.velocities = None
        self.personal_bests = None
        self.personal_best_fitness = None
        self.global_best = None
        self.global_best_fitness = float('inf')
        self._dimension = None

    def initialize(self):
        """Initialize the swarm."""
        super().initialize()
        
        if not self.population:
            return
        
        self._dimension = len(self.population[0].representation)
        self.velocities = self.rng.uniform(-1, 1, (self.population_size, self._dimension))
        self.personal_bests = np.array([np.asarray(sol.representation) for sol in self.population])
        self.personal_best_fitness = np.array([sol.fitness for sol in self.population])
        self._update_global_best()

    def _update_global_best(self):
        """Update global best."""
        if self.personal_best_fitness is not None:
            best_idx = np.argmin(self.personal_best_fitness)
            if self.personal_best_fitness[best_idx] < self.global_best_fitness:
                self.global_best = self.personal_bests[best_idx].copy()
                self.global_best_fitness = self.personal_best_fitness[best_idx]
        
        if self.global_best is not None:
            self.best_solution = Solution(self.global_best.astype(int).tolist(), self.problem)
            self.best_solution.fitness = self.global_best_fitness

    def step(self):
        """Vectorized PSO step."""
        self.ensure_population_evaluated()
        
        if self.velocities is None:
            self.initialize()
            return
        
        X = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        
        r1 = self.rng.random((self.population_size, self._dimension))
        r2 = self.rng.random((self.population_size, self._dimension))
        
        cognitive = self.c1 * r1 * (self.personal_bests - X)
        social = self.c2 * r2 * (self.global_best - X) if self.global_best is not None else 0
        
        self.velocities = self.omega * self.velocities + cognitive + social
        self.velocities = np.clip(self.velocities, -self.vmax, self.vmax)
        
        prob = 1.0 / (1.0 + np.exp(-2.0 * self.velocities))
        
        new_X = X.copy().astype(int)
        flip_to_1 = prob > 0.7
        flip_to_0 = prob < 0.3
        uncertain = ~flip_to_1 & ~flip_to_0
        
        new_X[flip_to_1] = 1
        new_X[flip_to_0] = 0
        new_X[uncertain] = (self.rng.random(uncertain.shape) < prob)[uncertain]
        
        new_population = []
        for i in range(self.population_size):
            sol = Solution(new_X[i].tolist(), self.problem)
            new_population.append(sol)
        
        self.population = new_population
        self.ensure_population_evaluated()
        
        for i in range(self.population_size):
            if self.population[i].fitness < self.personal_best_fitness[i]:
                self.personal_bests[i] = new_X[i].copy()
                self.personal_best_fitness[i] = self.population[i].fitness
        
        self._update_global_best()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1

    def ingest_population(self, seeds: List[Solution]):
        """Ingest population and re-initialize PSO state."""
        super().ingest_population(seeds)
        
        if not self.population:
            return
        
        self._dimension = len(self.population[0].representation)
        self.velocities = self.rng.uniform(-0.5, 0.5, (self.population_size, self._dimension))
        self.personal_bests = np.array([np.asarray(sol.representation) for sol in self.population])
        self.personal_best_fitness = np.array([sol.fitness for sol in self.population])
        self.global_best_fitness = float('inf')
        self.global_best = None
        self._update_global_best()


# =============================================================================
# Grey Wolf Optimizer - Exploiter Variant
# =============================================================================

class NKLGWOExploiter(BinaryMixin, SearchAlgorithm):
    """
    GWO configured for EXPLOITATION.
    
    Exploitation tuning:
    - Low 'a' decay (2.0 â†’ 0.0) - quick convergence
    - Small position updates - wolves converge tightly
    - No random leader selection
    - Very low mutation
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        a_initial: float = 2.0,      # Standard decay
        a_final: float = 0.0,        # Full convergence
        mutation_rate: float = 0.02,  # Very low mutation
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.a_initial = a_initial
        self.a_final = a_final
        self.mutation_rate = mutation_rate
        self._dimension = None
        self.max_iterations = kwargs.get('max_iterations', 1000)
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        # Sort by fitness
        sorted_pop = sorted(self.population, key=lambda s: s.fitness)
        alpha = np.asarray(sorted_pop[0].representation, dtype=float)
        beta = np.asarray(sorted_pop[1].representation, dtype=float)
        delta = np.asarray(sorted_pop[2].representation, dtype=float)
        
        # Fast decay to 0 for exploitation
        progress = min(1.0, self.iteration / max(1, self.max_iterations))
        a = self.a_initial * (1 - progress)  # Linear decay to 0
        
        new_population = []
        for wolf in self.population:
            x = np.asarray(wolf.representation, dtype=float)
            
            # Standard GWO update with low 'a'
            X1 = self._update_position(x, alpha, a)
            X2 = self._update_position(x, beta, a)
            X3 = self._update_position(x, delta, a)
            new_x = (X1 + X2 + X3) / 3
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            
            # Very light mutation
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_sol = Solution(binary.tolist(), self.problem)
            new_population.append(new_sol)
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1
    
    def _update_position(self, wolf, leader, a):
        r1 = self.rng.random(self._dimension)
        r2 = self.rng.random(self._dimension)
        A = 2 * a * r1 - a
        C = 2 * r2
        D = np.abs(C * leader - wolf)
        return leader - A * D


# =============================================================================
# Particle Swarm Optimization - Exploiter Variant
# =============================================================================

class NKLPSOExploiter(BinaryMixin, SearchAlgorithm):
    """
    PSO configured for EXPLOITATION.
    
    Exploitation tuning:
    - Low inertia weight (0.4) - particles converge quickly
    - Low cognitive coefficient (c1=1.0)
    - High social coefficient (c2=2.5) - strong swarm attraction
    - Low velocity limits - small steps
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        omega: float = 0.4,          # Low inertia for quick convergence
        c1: float = 1.0,             # Low cognitive
        c2: float = 2.5,             # High social (global best attraction)
        vmax: float = 4.0,           # Lower velocity limit
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.omega = omega
        self.c1 = c1
        self.c2 = c2
        self.vmax = vmax
        
        self.velocities = None
        self.personal_bests = None
        self.personal_best_fitness = None
        self.global_best = None
        self.global_best_fitness = float('inf')
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if not self.population:
            return
        
        self._dimension = len(self.population[0].representation)
        
        # Initialize velocities with lower variance for exploitation
        self.velocities = self.rng.uniform(-1, 1, (self.population_size, self._dimension))
        
        self.personal_bests = np.array([np.asarray(sol.representation) for sol in self.population])
        self.personal_best_fitness = np.array([sol.fitness for sol in self.population])
        
        self._update_global_best()
    
    def _update_global_best(self):
        if self.personal_best_fitness is not None:
            best_idx = np.argmin(self.personal_best_fitness)
            if self.personal_best_fitness[best_idx] < self.global_best_fitness:
                self.global_best = self.personal_bests[best_idx].copy()
                self.global_best_fitness = self.personal_best_fitness[best_idx]
        
        if self.global_best is not None:
            self.best_solution = Solution(self.global_best.astype(int).tolist(), self.problem)
            self.best_solution.fitness = self.global_best_fitness
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self.velocities is None:
            self.initialize()
            return
        
        X = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        
        # Velocity update with exploitation bias
        r1 = self.rng.random((self.population_size, self._dimension))
        r2 = self.rng.random((self.population_size, self._dimension))
        
        cognitive = self.c1 * r1 * (self.personal_bests - X)
        social = self.c2 * r2 * (self.global_best - X) if self.global_best is not None else 0
        
        self.velocities = self.omega * self.velocities + cognitive + social
        self.velocities = np.clip(self.velocities, -self.vmax, self.vmax)
        
        # Sigmoid probability for binary
        prob = 1.0 / (1.0 + np.exp(-self.velocities))
        
        # Deterministic update for exploitation (less stochasticity)
        new_X = (prob >= 0.5).astype(int)
        
        # Create new solutions
        new_population = []
        for i in range(self.population_size):
            sol = Solution(new_X[i].tolist(), self.problem)
            new_population.append(sol)
        
        self.population = new_population
        self.ensure_population_evaluated()
        
        # Update personal bests
        for i in range(self.population_size):
            if self.population[i].fitness < self.personal_best_fitness[i]:
                self.personal_bests[i] = new_X[i].copy()
                self.personal_best_fitness[i] = self.population[i].fitness
        
        self._update_global_best()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Genetic Algorithm - Exploiter Variant
# =============================================================================

class NKLGAExploiter(BinaryMixin, SearchAlgorithm):
    """
    GA configured for EXPLOITATION.
    
    Exploitation tuning:
    - Low mutation rate (0.02)
    - Single-point crossover (less disruption)
    - High tournament size (5) - strong selection pressure
    - High elitism (10%)
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        mutation_rate: float = 0.02,       # Very low mutation
        crossover_rate: float = 0.8,
        tournament_size: int = 5,           # High selection pressure
        elitism_rate: float = 0.1,          # Keep top 10%
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.mutation_rate = mutation_rate
        self.crossover_rate = crossover_rate
        self.tournament_size = tournament_size
        self.elitism_rate = elitism_rate
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        new_population = []
        
        # Elitism - keep top
        sorted_pop = sorted(self.population, key=lambda s: s.fitness)
        n_elite = max(1, int(self.population_size * self.elitism_rate))
        for i in range(n_elite):
            new_population.append(sorted_pop[i].copy(preserve_id=False))
        
        # Generate offspring
        while len(new_population) < self.population_size:
            # Strong tournament selection
            parent1 = self._tournament_select()
            parent2 = self._tournament_select()
            
            # Single-point crossover (less disruption)
            if self.rng.random() < self.crossover_rate:
                child1, child2 = self._single_point_crossover(parent1, parent2)
            else:
                child1 = np.asarray(parent1.representation).copy()
                child2 = np.asarray(parent2.representation).copy()
            
            # Very low mutation
            child1 = self._bit_flip_mutation(child1, self.mutation_rate)
            child2 = self._bit_flip_mutation(child2, self.mutation_rate)
            
            new_population.append(Solution(child1.tolist(), self.problem))
            if len(new_population) < self.population_size:
                new_population.append(Solution(child2.tolist(), self.problem))
        
        self.population = new_population[:self.population_size]
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1
    
    def _tournament_select(self) -> Solution:
        candidates = self.rng.choice(self.population, size=self.tournament_size, replace=False)
        return min(candidates, key=lambda s: s.fitness)
    
    def _single_point_crossover(self, p1: Solution, p2: Solution) -> Tuple[np.ndarray, np.ndarray]:
        a1 = np.asarray(p1.representation)
        a2 = np.asarray(p2.representation)
        point = self.rng.integers(1, self._dimension)
        c1 = np.concatenate([a1[:point], a2[point:]])
        c2 = np.concatenate([a2[:point], a1[point:]])
        return c1, c2


# =============================================================================
# L-SHADE - Exploiter Variant (Natural exploiter)
# =============================================================================

class NKLLSHADEExploiter(BinaryMixin, SearchAlgorithm):
    """
    L-SHADE configured for EXPLOITATION.
    
    L-SHADE is naturally adaptive and converges well.
    Additional exploitation tuning:
    - Low p_best_rate (use only top solutions)
    - History biased toward exploitation
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        p_best_rate: float = 0.05,    # Only top 5% as targets (strong exploitation)
        archive_rate: float = 1.0,
        H: int = 5,                    # History size
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.p_best_rate = p_best_rate
        self.archive_rate = archive_rate
        self.H = H
        self._dimension = None
        
        # Adaptive parameters
        self.memory_F = np.full(H, 0.5)  # Mutation factor memory
        self.memory_CR = np.full(H, 0.9) # Crossover rate memory (high for convergence)
        self.memory_index = 0
        self.archive = []
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        fitness = np.array([sol.fitness for sol in self.population])
        sorted_idx = np.argsort(fitness)
        
        # Select p_best (very few for exploitation)
        p_best_num = max(1, int(self.population_size * self.p_best_rate))
        
        new_population = []
        S_F, S_CR = [], []
        delta_f = []
        
        for i in range(self.population_size):
            target = np.asarray(self.population[i].representation, dtype=float)
            
            # Sample parameters from memory
            r_idx = self.rng.integers(self.H)
            F = np.clip(self.rng.standard_cauchy() * 0.1 + self.memory_F[r_idx], 0.1, 1.0)
            CR = np.clip(self.rng.normal(self.memory_CR[r_idx], 0.1), 0.0, 1.0)
            
            # current-to-pbest/1 mutation
            p_best_idx = sorted_idx[self.rng.integers(p_best_num)]
            p_best = np.asarray(self.population[p_best_idx].representation, dtype=float)
            
            r1 = self.rng.integers(self.population_size)
            while r1 == i:
                r1 = self.rng.integers(self.population_size)
            
            # Choose r2 from population or archive
            combined = self.population + self.archive
            r2 = self.rng.integers(len(combined))
            while r2 == i or r2 == r1:
                r2 = self.rng.integers(len(combined))
            
            x_r1 = np.asarray(self.population[r1].representation, dtype=float)
            x_r2 = np.asarray(combined[r2].representation, dtype=float)
            
            mutant = target + F * (p_best - target) + F * (x_r1 - x_r2)
            mutant = np.clip(mutant, 0, 1)
            
            # Binomial crossover
            trial = target.copy()
            j_rand = self.rng.integers(self._dimension)
            for j in range(self._dimension):
                if self.rng.random() < CR or j == j_rand:
                    trial[j] = mutant[j]
            
            trial_binary = self._to_binary(trial)
            trial_sol = Solution(trial_binary.tolist(), self.problem)
            trial_sol.evaluate()
            
            if trial_sol.fitness <= self.population[i].fitness:
                if trial_sol.fitness < self.population[i].fitness:
                    self.archive.append(self.population[i])
                    S_F.append(F)
                    S_CR.append(CR)
                    delta_f.append(abs(self.population[i].fitness - trial_sol.fitness))
                new_population.append(trial_sol)
            else:
                new_population.append(self.population[i])
        
        # Truncate archive
        max_archive = int(self.archive_rate * self.population_size)
        while len(self.archive) > max_archive:
            self.archive.pop(self.rng.integers(len(self.archive)))
        
        # Update memories
        if S_F:
            weights = np.array(delta_f)
            weights = weights / (weights.sum() + 1e-10)
            
            mean_F = np.sum(weights * np.array(S_F))
            mean_CR = np.sum(weights * np.array(S_CR))
            
            self.memory_F[self.memory_index] = mean_F
            self.memory_CR[self.memory_index] = mean_CR
            self.memory_index = (self.memory_index + 1) % self.H
        
        self.population = new_population
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Whale Optimization Algorithm - Exploiter Variant
# =============================================================================

class NKLWOAExploiter(BinaryMixin, SearchAlgorithm):
    """
    WOA configured for EXPLOITATION.
    
    Exploitation tuning:
    - Fast 'a' decay (|A| < 1 more often = exploitation)
    - High encircling probability
    - Tight spiral (low b)
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        a_initial: float = 2.0,
        a_final: float = 0.0,        # Full decay
        spiral_b: float = 0.5,       # Tight spiral
        encircle_prob: float = 0.7,  # High encircling
        mutation_rate: float = 0.02,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.a_initial = a_initial
        self.a_final = a_final
        self.spiral_b = spiral_b
        self.encircle_prob = encircle_prob
        self.mutation_rate = mutation_rate
        self._dimension = None
        self.max_iterations = kwargs.get('max_iterations', 1000)
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        fitness = np.array([sol.fitness for sol in self.population])
        best_idx = np.argmin(fitness)
        best = np.asarray(self.population[best_idx].representation, dtype=float)
        
        # Fast decay for exploitation
        progress = min(1.0, self.iteration / max(1, self.max_iterations))
        a = self.a_initial * (1 - progress)
        
        new_population = []
        for i, whale in enumerate(self.population):
            x = np.asarray(whale.representation, dtype=float)
            
            r1, r2 = self.rng.random(), self.rng.random()
            A = 2 * a * r1 - a
            C = 2 * r2
            p = self.rng.random()
            
            if p < self.encircle_prob:
                # Encircling prey (exploitation)
                D = np.abs(C * best - x)
                new_x = best - A * D
            else:
                # Tight spiral
                l = self.rng.uniform(-1, 1)
                D = np.abs(best - x)
                new_x = D * np.exp(self.spiral_b * l) * np.cos(2 * np.pi * l) + best
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_population.append(Solution(binary.tolist(), self.problem))
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Harris Hawks Optimization - Exploiter Variant
# =============================================================================

class NKLHHOExploiter(BinaryMixin, SearchAlgorithm):
    """
    HHO configured for EXPLOITATION.
    
    Exploitation tuning:
    - Force exploitation phase (E < 0.5)
    - Rapid perching and bounding pursuit
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        exploitation_bias: float = 0.8,   # Bias toward exploitation mode
        levy_steps: int = 3,              # Levy flight steps for local search
        mutation_rate: float = 0.02,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.exploitation_bias = exploitation_bias
        self.levy_steps = levy_steps
        self.mutation_rate = mutation_rate
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def _levy_flight(self, dim: int) -> np.ndarray:
        """Generate Levy flight step."""
        beta = 1.5
        sigma = (math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / 
                 (math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)
        u = self.rng.normal(0, sigma, dim)
        v = self.rng.normal(0, 1, dim)
        return u / (np.abs(v) ** (1 / beta))
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        positions = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        fitness = np.array([sol.fitness for sol in self.population])
        best_idx = np.argmin(fitness)
        rabbit = positions[best_idx].copy()
        
        new_population = []
        for i in range(self.population_size):
            x = positions[i]
            
            # Force exploitation mode
            E = self.rng.uniform(-0.5, 0.5) if self.rng.random() < self.exploitation_bias else self.rng.uniform(-1, 1)
            J = 2 * (1 - self.rng.random())  # Jump strength
            r = self.rng.random()
            
            if abs(E) < 1:  # Exploitation
                if r >= 0.5 and abs(E) >= 0.5:
                    # Soft besiege
                    new_x = rabbit - E * np.abs(J * rabbit - x)
                elif r >= 0.5 and abs(E) < 0.5:
                    # Hard besiege
                    new_x = rabbit - E * np.abs(rabbit - x)
                elif r < 0.5 and abs(E) >= 0.5:
                    # Soft besiege with progressive rapid dives
                    Y = rabbit - E * np.abs(J * rabbit - x)
                    Z = Y + self._levy_flight(self._dimension)
                    new_x = Y if self._eval_fitness(Y) < self._eval_fitness(Z) else Z
                else:
                    # Hard besiege with progressive rapid dives
                    Y = rabbit - E * np.abs(J * rabbit - np.mean(positions, axis=0))
                    Z = Y + self._levy_flight(self._dimension)
                    new_x = Y if self._eval_fitness(Y) < self._eval_fitness(Z) else Z
            else:
                # Random search (rare due to exploitation bias)
                rand_idx = self.rng.integers(self.population_size)
                rand_hawk = positions[rand_idx]
                new_x = rand_hawk - self.rng.random(self._dimension) * np.abs(rand_hawk - 2 * self.rng.random(self._dimension) * x)
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_population.append(Solution(binary.tolist(), self.problem))
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1
    
    def _eval_fitness(self, x: np.ndarray) -> float:
        """Quick fitness evaluation."""
        binary = self._to_binary(np.clip(x, 0, 1))
        sol = Solution(binary.tolist(), self.problem)
        sol.evaluate()
        return sol.fitness


# =============================================================================
# Marine Predators Algorithm - Exploiter Variant
# =============================================================================

class NKLMPAExploiter(BinaryMixin, SearchAlgorithm):
    """
    MPA configured for EXPLOITATION.
    
    Exploitation tuning:
    - Force phase 3 (Levy movement + exploitation)
    - Low FAD probability
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        fad_probability: float = 0.05,    # Very low random jumps
        levy_scale: float = 0.5,          # Controlled Levy steps
        mutation_rate: float = 0.02,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.fad_probability = fad_probability
        self.levy_scale = levy_scale
        self.mutation_rate = mutation_rate
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def _levy_flight(self, dim: int) -> np.ndarray:
        beta = 1.5
        sigma = (math.gamma(1 + beta) * np.sin(np.pi * beta / 2) / 
                 (math.gamma((1 + beta) / 2) * beta * 2 ** ((beta - 1) / 2))) ** (1 / beta)
        u = self.rng.normal(0, sigma, dim)
        v = self.rng.normal(0, 1, dim)
        return self.levy_scale * u / (np.abs(v) ** (1 / beta))
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        positions = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        fitness = np.array([sol.fitness for sol in self.population])
        best_idx = np.argmin(fitness)
        best = positions[best_idx].copy()
        
        new_population = []
        for i in range(self.population_size):
            x = positions[i]
            
            # Phase 3: Levy movement exploitation
            RL = self._levy_flight(self._dimension)
            new_x = best + RL * (best - x)
            
            # Rare FAD
            if self.rng.random() < self.fad_probability:
                r = self.rng.random(self._dimension)
                new_x = x + (0.1 - 0.05) * (1 - r) * x  # Small perturbation
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_population.append(Solution(binary.tolist(), self.problem))
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Slime Mould Algorithm - Exploiter Variant
# =============================================================================

class NKLSMAExploiter(BinaryMixin, SearchAlgorithm):
    """
    SMA configured for EXPLOITATION.
    
    Exploitation tuning:
    - Low random position probability
    - Strong weight-based attraction to best
    - Fitness-proportional weights
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        random_position_prob: float = 0.03,  # Very low random
        mutation_rate: float = 0.02,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.random_position_prob = random_position_prob
        self.mutation_rate = mutation_rate
        self._dimension = None
        self.max_iterations = kwargs.get('max_iterations', 1000)
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        positions = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        fitness = np.array([sol.fitness for sol in self.population])
        idx_sorted = np.argsort(fitness)
        best = positions[idx_sorted[0]]
        
        # Calculate weights based on fitness rank
        bF = fitness.min()
        wF = fitness.max()
        weights = np.zeros(self.population_size)
        for i in range(self.population_size):
            rank = np.where(idx_sorted == i)[0][0]
            if rank <= self.population_size // 2:
                weights[i] = 1 + self.rng.random() * np.log10((bF - fitness[i]) / (bF - wF + 1e-10) + 1)
            else:
                weights[i] = 1 - self.rng.random() * np.log10((bF - fitness[i]) / (bF - wF + 1e-10) + 1)
        
        # z parameter based on iteration
        z = 1 - self.iteration / max(1, self.max_iterations)
        
        new_population = []
        for i in range(self.population_size):
            x = positions[i]
            
            if self.rng.random() < self.random_position_prob:
                new_x = self.rng.random(self._dimension)
            else:
                # Slime movement toward best
                j, k = self.rng.choice(self.population_size, size=2, replace=False)
                p = np.tanh(np.abs(fitness[i] - bF))
                vc = np.sign(self.rng.random(self._dimension) - 0.5)
                
                if self.rng.random() < p:
                    new_x = best + vc * weights[i] * (positions[j] - positions[k])
                else:
                    new_x = x + vc * (z * (bF - x) + (1 - z) * (positions[j] - positions[k]))
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_population.append(Solution(binary.tolist(), self.problem))
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Gravitational Search Algorithm - Exploiter Variant
# =============================================================================

class NKLGSAExploiter(BinaryMixin, SearchAlgorithm):
    """
    GSA configured for EXPLOITATION.
    
    Exploitation tuning:
    - Lower initial G0
    - Faster decay (high alpha)
    - K_best reduces quickly
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        G0: float = 100.0,           # Lower initial G
        alpha: float = 30.0,          # Fast decay
        mutation_rate: float = 0.02,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.G0 = G0
        self.alpha = alpha
        self.mutation_rate = mutation_rate
        self._dimension = None
        self.velocities = None
        self.max_iterations = kwargs.get('max_iterations', 1000)
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
            self.velocities = np.zeros((self.population_size, self._dimension))
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None:
            self.initialize()
            return
        
        positions = np.array([np.asarray(sol.representation, dtype=float) for sol in self.population])
        fitness = np.array([sol.fitness for sol in self.population])
        
        # Calculate G with fast decay
        t = self.iteration / max(1, self.max_iterations)
        G = self.G0 * np.exp(-self.alpha * t)
        
        # Calculate masses
        worst = fitness.max()
        best = fitness.min()
        if np.isclose(worst, best):
            masses = np.ones(self.population_size)
        else:
            masses = (worst - fitness) / (worst - best + 1e-10)
        masses = masses / (masses.sum() + 1e-10)
        
        # K_best: only best agents exert force (decreases over time)
        K = max(1, int(self.population_size * (1 - t)))
        sorted_idx = np.argsort(fitness)
        best_agents = sorted_idx[:K]
        
        new_population = []
        for i in range(self.population_size):
            force = np.zeros(self._dimension)
            for j in best_agents:
                if i != j:
                    R = np.linalg.norm(positions[i] - positions[j]) + 1e-10
                    direction = positions[j] - positions[i]
                    force += self.rng.random() * G * masses[j] * direction / R
            
            acc = force
            self.velocities[i] = self.rng.random() * self.velocities[i] + acc
            new_x = positions[i] + self.velocities[i]
            
            new_x = np.clip(new_x, 0, 1)
            binary = self._to_binary(new_x)
            binary = self._bit_flip_mutation(binary, self.mutation_rate)
            
            new_population.append(Solution(binary.tolist(), self.problem))
        
        self.population = new_population
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Hill Climbing - Pure Local Search Exploiter
# =============================================================================

class NKLHillClimbingExploiter(BinaryMixin, SearchAlgorithm):
    """
    Hill Climbing - Pure local search for exploitation.
    
    Key properties:
    - Single-bit flips
    - Steepest ascent selection
    - No random restarts (pure exploitation)
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        n_neighbors: int = 10,        # Number of neighbors to evaluate per step
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.n_neighbors = n_neighbors
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        new_population = []
        for ind in self.population:
            current = np.asarray(ind.representation)
            current_fit = ind.fitness
            
            # Generate neighbors by single bit flips
            best_neighbor = current.copy()
            best_neighbor_fit = current_fit
            
            # Try flipping each bit (or subset)
            flip_positions = self.rng.choice(self._dimension, 
                                             size=min(self.n_neighbors, self._dimension),
                                             replace=False)
            
            for pos in flip_positions:
                neighbor = current.copy()
                neighbor[pos] = 1 - neighbor[pos]
                
                sol = Solution(neighbor.tolist(), self.problem)
                sol.evaluate()
                
                if sol.fitness < best_neighbor_fit:
                    best_neighbor = neighbor
                    best_neighbor_fit = sol.fitness
            
            # Move to best neighbor if improvement (steepest ascent)
            if best_neighbor_fit < current_fit:
                new_sol = Solution(best_neighbor.tolist(), self.problem)
                new_sol.fitness = best_neighbor_fit
                new_population.append(new_sol)
            else:
                # Stay at current position
                new_population.append(ind.copy(preserve_id=False))
        
        self.population = new_population
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1


# =============================================================================
# Memetic Algorithm - Exploiter (GA + Local Search)
# =============================================================================

class NKLMemeticExploiter(BinaryMixin, SearchAlgorithm):
    """
    Memetic Algorithm - GA with intensive local search.
    
    Exploitation tuning:
    - High local search frequency
    - Multiple local search iterations
    - Strong selection pressure
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        mutation_rate: float = 0.02,
        local_search_prob: float = 0.8,     # Apply LS to 80% of population
        local_search_steps: int = 10,       # LS iterations
        tournament_size: int = 5,
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.mutation_rate = mutation_rate
        self.local_search_prob = local_search_prob
        self.local_search_steps = local_search_steps
        self.tournament_size = tournament_size
        self._dimension = None
    
    def initialize(self):
        super().initialize()
        if self.population:
            self._dimension = len(self.population[0].representation)
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None and self.population:
            self._dimension = len(self.population[0].representation)
        
        # GA part
        new_population = []
        best = min(self.population, key=lambda s: s.fitness)
        new_population.append(best.copy(preserve_id=False))
        
        while len(new_population) < self.population_size:
            p1 = self._tournament_select()
            p2 = self._tournament_select()
            child = self._crossover(p1, p2)
            child = self._bit_flip_mutation(child, self.mutation_rate)
            
            # Local search with probability
            if self.rng.random() < self.local_search_prob:
                child = self._local_search(child)
            
            new_population.append(Solution(child.tolist(), self.problem))
        
        self.population = new_population[:self.population_size]
        self.ensure_population_evaluated()
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1
    
    def _tournament_select(self) -> Solution:
        candidates = self.rng.choice(self.population, size=self.tournament_size, replace=False)
        return min(candidates, key=lambda s: s.fitness)
    
    def _crossover(self, p1: Solution, p2: Solution) -> np.ndarray:
        a1 = np.asarray(p1.representation)
        a2 = np.asarray(p2.representation)
        point = self.rng.integers(1, self._dimension)
        return np.concatenate([a1[:point], a2[point:]])
    
    def _local_search(self, x: np.ndarray) -> np.ndarray:
        """Steepest ascent hill climbing."""
        current = x.copy()
        sol = Solution(current.tolist(), self.problem)
        sol.evaluate()
        current_fit = sol.fitness
        
        for _ in range(self.local_search_steps):
            improved = False
            # Try all single-bit flips
            best_pos = -1
            best_fit = current_fit
            
            for pos in range(self._dimension):
                neighbor = current.copy()
                neighbor[pos] = 1 - neighbor[pos]
                
                sol = Solution(neighbor.tolist(), self.problem)
                sol.evaluate()
                
                if sol.fitness < best_fit:
                    best_fit = sol.fitness
                    best_pos = pos
                    improved = True
            
            if improved:
                current[best_pos] = 1 - current[best_pos]
                current_fit = best_fit
            else:
                break
        
        return current


# =============================================================================
# ABC - Exploiter (Natural exploitation via greedy selection)
# =============================================================================

class NKLABCExploiter(BinaryMixin, SearchAlgorithm):
    """
    ABC configured for EXPLOITATION.
    
    Exploitation tuning:
    - High limit (few scouts = less exploration)
    - Low perturbation scale
    - No additional mutation
    """
    phase = "exploitation"
    
    def __init__(
        self,
        problem: ProblemInterface,
        population_size: int,
        *,
        limit_factor: float = 3.0,         # High = fewer scouts
        perturbation_scale: float = 0.2,   # Low perturbation
        seed: Optional[int] = None,
        **kwargs,
    ):
        super().__init__(problem, population_size, **kwargs)
        self.rng = np.random.default_rng(seed)
        self.limit_factor = limit_factor
        self.perturbation_scale = perturbation_scale
        self._dimension = None
        self.trial_counters = []
        self.limit = None
    
    def initialize(self):
        super().initialize()
        if not self.population:
            return
        self._dimension = len(self.population[0].representation)
        self.limit = max(10, int(self.limit_factor * self.population_size * self._dimension))
        self.trial_counters = [0] * self.population_size
        self._update_best_solution()
    
    def step(self):
        self.ensure_population_evaluated()
        
        if self._dimension is None:
            self.initialize()
            return
        
        # Employed bee phase
        for i in range(self.population_size):
            neighbor = self._generate_neighbor(i)
            if neighbor.fitness <= self.population[i].fitness:
                self.population[i] = neighbor
                self.trial_counters[i] = 0
            else:
                self.trial_counters[i] += 1
        
        # Calculate selection probabilities (fitness proportional)
        fitness = np.array([sol.fitness for sol in self.population])
        min_fit = fitness.min()
        adjusted = fitness - min_fit + 1e-10
        probs = 1.0 / adjusted
        probs = probs / probs.sum()
        
        # Onlooker phase - focus on best solutions
        for _ in range(self.population_size):
            idx = self.rng.choice(self.population_size, p=probs)
            neighbor = self._generate_neighbor(idx)
            if neighbor.fitness <= self.population[idx].fitness:
                self.population[idx] = neighbor
                self.trial_counters[idx] = 0
            else:
                self.trial_counters[idx] += 1
        
        # Scout phase - rare due to high limit
        for i in range(self.population_size):
            if self.trial_counters[i] >= self.limit:
                new_binary = self._random_binary(self._dimension)
                self.population[i] = Solution(new_binary.tolist(), self.problem)
                self.population[i].evaluate()
                self.trial_counters[i] = 0
        
        self.mark_best_dirty()
        self._update_best_solution()
        self.iteration += 1
    
    def _generate_neighbor(self, idx: int) -> Solution:
        current = np.asarray(self.population[idx].representation)
        
        # Select random partner
        partner_idx = self.rng.integers(self.population_size)
        while partner_idx == idx:
            partner_idx = self.rng.integers(self.population_size)
        partner = np.asarray(self.population[partner_idx].representation)
        
        # Generate neighbor with low perturbation
        n_flip = max(1, int(self._dimension * self.perturbation_scale * self.rng.random()))
        positions = self.rng.choice(self._dimension, size=n_flip, replace=False)
        
        neighbor = current.copy()
        for pos in positions:
            if self.rng.random() < 0.5:
                neighbor[pos] = partner[pos]
            else:
                neighbor[pos] = 1 - neighbor[pos]
        
        sol = Solution(neighbor.tolist(), self.problem)
        sol.evaluate()
        return sol
